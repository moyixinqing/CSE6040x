{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 15: The Forward Pass of a Neural Network\n",
    "\n",
    "_Version 1.2_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Neural networks are a set of algorithms for pattern recognition. They are loosely inspired by the human brain, and have proven especially useful in data clustering and classification tasks.\n",
    "\n",
    "In this problem, you will use your knowledge of Python and Numpy to speed-up a common computational kernel that arises in neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Example: a \"fully connected layer\" for images.** Suppose the data we are analyzing consists of $N$ two-dimensional images of size $H \\times W$ pixels each. In a neural network, a typical substep is the evaluation of a \"fully connected (FC) layer,\" which takes the images as input and produces a vector of outputs, with one vector per image.\n",
    "\n",
    "Mathematically, here is a simplified example of what a typical FC layer calculation might look like. Let $x[k, i, j]$ denote the value (e.g., intensity) of the pixel at location $(i, j)$ of the $k$-th input image. Since there are $N$ images, take the values of $k$ to be in the range of 0 to $N-1$, respectively. And since each image is $H \\times W$, take $0 \\leq i \\leq H-1$ and $0 \\leq j \\leq W-1$. Next, let $\\mathrm{out}[k, l]$ denote an output value in the $l$-th element of a vector associated with image $k$, where $0 \\leq l \\leq M-1$, for some given value of $M$. Lastly, suppose the specific  formula for transforming the input images into this collection of output vectors is given by the formula,\n",
    "\n",
    "$$\n",
    "\\mathrm{out}[k, l] = b[l] + \\sum_{i=0}^{H-1} \\sum_{j=0}^{W-1} \\left(x[k, i, j] \\times w[l, i, j]\\right)\n",
    "$$\n",
    "\n",
    "where $w[l, i, j]$ are \"weights\" and $b[l]$ are \"biases.\" The process of \"training\" the neural network from sample data determines these weight and bias parameters, but for this problem, just assume that they are given.\n",
    "\n",
    "If it's helpful, here is a picture of what this formula is doing for each $(k, l)$ pair:\n",
    "<img src = \"fully_connected.png\" width = \"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**The baseline implementation.** In the code cells below, we define a Python function, `FC_naive(x, w, b)`, that implements the FC layer calculation from above using a straightforward, albeit somewhat naive, method. Your goal is to make this baseline run faster.\n",
    "\n",
    "To start, first run the next three code cells to estimate the time of the baseline implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from cse6040bench import benchit\n",
    "\n",
    "def rel_error(x, y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def FC_naive(x, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - x: A numpy array of images of shape (N, H, W)\n",
    "    - w: A numpy array of weights of shape (M, H, W)\n",
    "    - b: A numpy vector of biases of size M\n",
    "\n",
    "    Returns: \n",
    "    - out: a numpy array of shape (N, M)\n",
    "    \"\"\"\n",
    "    N, H, W = x.shape\n",
    "    M, _, _ = w.shape\n",
    "    out = np.zeros((N,M))\n",
    "    for ni in range(N):\n",
    "        for mi in range(M):\n",
    "                out[ni,mi] = b[mi]\n",
    "                for d1 in range(H):\n",
    "                    for d2 in range(W):\n",
    "                        out[ni,mi] += x[ni, d1, d2] * w[mi, d1, d2] \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Took 11.9715 seconds.\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 50\n",
    "input_shape = (128, 256)\n",
    "output_dim = 10\n",
    "\n",
    "x = np.random.rand(num_inputs, *input_shape)\n",
    "w = np.random.rand(output_dim, *input_shape)\n",
    "b = np.random.rand(output_dim)\n",
    "start_time = time.time ()\n",
    "out = FC_naive(x, w, b)\n",
    "elapsed_time = time.time () - start_time\n",
    "print (\"==> Took %g seconds.\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (5 points). Let's start by seeing if we can make `FC_naive()` function faster by rewriting the two innermost loops, i.e., the `d1` and `d2` loops:\n",
    "\n",
    "```python\n",
    "for d1 in range(H):\n",
    "    for d2 in range(W):\n",
    "        out[ni, mi] += x[ni, d1, d2] * w[mi, d1, d2]\n",
    "```\n",
    "\n",
    "For this exercise, complete the function `two_inner_loops(x_i, w_l, b_j)`, below, so that it implements the same computation as these two `d1` and `d2` loops, but is much faster. It should return `out[ni, mi]`. The input `x_i` is the `i`-th image, `w_l` is the `l`-th weight matrix, and `b_l` is the `l`-th component of the bias vector.\n",
    "\n",
    "The test code will check your results and benchmark a complete FC layer using the function `FC_two_loops()`, defined below. You'll see that it calls your `two_inner_loops()` routine to implement the two innermost loops.\n",
    "\n",
    "To get credit on this exercise, the resulting execution time of `FC_two_loops()` must be at least **100 times faster** than `FC_naive()` on the problem sizes being tested below when running on the Vocareum platform. There is no partial credit for smaller speedups. Having said that, a little bit of basic Numpy should go a long way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_inner_loops(x_i, w_l, b_l):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - x_i: A numpy array of images of shape (H, W)\n",
    "    - w_l: A numpy array of weights of shape (H, W)\n",
    "    - b_l: A float (single number)\n",
    "\n",
    "    Returns: \n",
    "    - out: A float (single number)\n",
    "    \"\"\"\n",
    "    ###\n",
    "    return sum(sum(x_i*w_l)) + b_l\n",
    "    \n",
    "    \n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "FC_two_loops",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the correctness of your implementation...\n",
      "==> Output error: 7.336712599166417e-15\n",
      "==> This level of error is acceptable.\n",
      "\n",
      "Benchmarking your code...\n",
      "Timing result: (5 trials) x (10 runs) in 4.036131970991846 secs\n",
      "==> 0.08072263941983693 secs per run\n",
      "==> Took 0.0807226 seconds.\n",
      "\n",
      "Benchmarking the naive code...\n",
      "Timing result: (5 trials) x (1 runs) in 59.44502844201634 secs\n",
      "==> 11.889005688403268 secs per run\n",
      "==> Took 11.889 seconds.\n",
      "Speed-up: 147.2821723106547\n",
      "\n",
      "(Passed!)\n"
     ]
    }
   ],
   "source": [
    "# Test cell: 'FC_two_loops_1' (5 points)\n",
    "\n",
    "def FC_two_loops(x, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - x: A numpy array of images of shape (N, H, W)\n",
    "    - w: A numpy array of weights of shape (M, H, W)\n",
    "    - b: A numpy vector of biases of size M\n",
    "\n",
    "    Returns: \n",
    "    - out: a numpy array of shape (N, M)\n",
    "    \"\"\"\n",
    "    N, H, W = x.shape\n",
    "    M, _, _ = w.shape\n",
    "    out = np.zeros((N,M))\n",
    "    for ni in range(N):\n",
    "           for mi in range(M):\n",
    "                out[ni, mi] = two_inner_loops(x[ni,  :, :], w[mi,  :, :], b[mi])\n",
    "    return out\n",
    "\n",
    "num_inputs = 50\n",
    "input_shape = (128, 256)\n",
    "output_dim = 10\n",
    "\n",
    "x = np.random.rand(num_inputs, *input_shape)\n",
    "w = np.random.rand(output_dim, *input_shape)\n",
    "b = np.random.rand(output_dim)\n",
    "\n",
    "print(\"Checking the correctness of your implementation...\")\n",
    "out_fast = FC_two_loops(x, w, b)\n",
    "out_naive = FC_naive(x, w, b)\n",
    "error = rel_error(out_naive, out_fast)\n",
    "print(\"==> Output error:\", error)\n",
    "assert error < 1e-12, \"The value of your output is incorrect or not accurate enough\"\n",
    "print(\"==> This level of error is acceptable.\")\n",
    "\n",
    "print(\"\\nBenchmarking your code...\")\n",
    "T_fast = benchit(\"FC_two_loops(x, w, b)\", scope=globals())\n",
    "elapsed_time_fast = T_fast['mean_time_per_run']\n",
    "print (\"==> Took %g seconds.\" % elapsed_time_fast)\n",
    "\n",
    "print(\"\\nBenchmarking the naive code...\")\n",
    "T_naive = benchit(\"FC_naive(x, w, b)\", scope=globals())\n",
    "elapsed_time_naive = T_naive['mean_time_per_run']\n",
    "print (\"==> Took %g seconds.\" % elapsed_time_naive)\n",
    "\n",
    "speed_up = elapsed_time_naive / elapsed_time_fast\n",
    "print(\"Speed-up:\", speed_up)\n",
    "assert speed_up >= 100, \"The speed-up of your method is less than 100\"\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Question 2** (5 points). Now, completely rewrite the `FC_naive()` function by at least **2,000 times**.\n",
    "\n",
    "> This improvement can be attained with basic Numpy operations that you've learned (i.e., no \"new\" functions) and no explicit loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_no_loop(x, w, b):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - x: A numpy array of images of shape (N, H, W)\n",
    "    - w: A numpy array of weights of shape (M, H, W)\n",
    "    - b: A numpy vector of biases of size M\n",
    "\n",
    "    Returns: \n",
    "    - out: a numpy array of shape (N, M)\n",
    "    \"\"\"\n",
    "    N, H, W = x.shape\n",
    "    M, _, _ = w.shape\n",
    "    out = np.zeros((N,M))\n",
    "    ###\n",
    "    out = np.inner(x.reshape(N,-1),w.reshape(M,-1))+b\n",
    "\n",
    "    ###\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M, _, _ = w.shape\n",
    "n= w.reshape(M,-1)\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "FC_no_loop",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the correctness of your implementation...\n",
      "==> Output error: 7.947338556292e-15\n",
      "==> This level of error is acceptable.\n",
      "\n",
      "Benchmarking your code...\n",
      "Timing result: (5 trials) x (1000 runs) in 7.721795499935979 secs\n",
      "==> 0.0015443590999871957 secs per run\n",
      "==> Took 0.00154436 seconds.\n",
      "\n",
      "Benchmarking the naive code...\n",
      "Timing result: (5 trials) x (1 runs) in 60.06017509903177 secs\n",
      "==> 12.012035019806353 secs per run\n",
      "==> Took 12.012 seconds.\n",
      "Speed-up: 7778.006436395489\n",
      "\n",
      "(Passed!)\n"
     ]
    }
   ],
   "source": [
    "# Test cell: 'FC_no_loop' (5 points)\n",
    "num_inputs = 50\n",
    "input_shape = (128, 256)\n",
    "output_dim = 10\n",
    "\n",
    "x = np.random.rand(num_inputs, *input_shape)\n",
    "w = np.random.rand(output_dim, *input_shape)\n",
    "b = np.random.rand(output_dim)\n",
    "\n",
    "print(\"Checking the correctness of your implementation...\")\n",
    "out_fast = FC_no_loop(x, w, b)\n",
    "out_naive = FC_naive(x, w, b)\n",
    "error = rel_error(out_naive, out_fast)\n",
    "print(\"==> Output error:\", error)\n",
    "assert error < 1e-12, \"The value of your output is incorrect or not accurate enough\"\n",
    "print(\"==> This level of error is acceptable.\")\n",
    "\n",
    "print(\"\\nBenchmarking your code...\")\n",
    "T_fast = benchit(\"FC_no_loop(x, w, b)\", scope=globals())\n",
    "elapsed_time_fast = T_fast['mean_time_per_run']\n",
    "print (\"==> Took %g seconds.\" % elapsed_time_fast)\n",
    "\n",
    "print(\"\\nBenchmarking the naive code...\")\n",
    "T_naive = benchit(\"FC_naive(x, w, b)\", scope=globals())\n",
    "elapsed_time_naive = T_naive['mean_time_per_run']\n",
    "print (\"==> Took %g seconds.\" % elapsed_time_naive)\n",
    "\n",
    "speed_up = elapsed_time_naive / elapsed_time_fast\n",
    "print(\"Speed-up:\", speed_up)\n",
    "assert speed_up >= 2000, \"The speed-up of your method is less than 2000\"\n",
    "\n",
    "print(\"\\n(Passed!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** You've reached the end of this problem. Don't forget to restart the\n",
    "kernel and run the entire notebook from top-to-bottom to make sure you did\n",
    "everything correctly. If that is working, try submitting this problem. (Recall\n",
    "that you *must* submit and pass the autograder to get credit for your work!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
